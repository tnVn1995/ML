{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T21:34:18.195883Z",
     "start_time": "2020-04-04T21:34:18.101116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "import text_normalize as tn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from IPython.core.debugger import set_trace\n",
    "# Model building\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieval and Preprocessing\n",
    "\n",
    "We will strip HTML markups, expand contractions such as can't into cannot, remove accented character, lowercase all words, lemmatize, remove special characters and stopwords from out text corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T21:34:21.879000Z",
     "start_time": "2020-04-04T21:34:19.358742Z"
    }
   },
   "outputs": [],
   "source": [
    "data = fetch_20newsgroups(subset='all', shuffle=True,\n",
    "                          remove=('headers', 'footers', 'quotes'))\n",
    "data_labels_map = dict(enumerate(data.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T21:34:23.192491Z",
     "start_time": "2020-04-04T21:34:23.091766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18846, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Target Label</th>\n",
       "      <th>Target Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nI am sure some bashers of Pens fans are pr...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My brother is in the market for a high-perform...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\n\\n\\tFinally you said what you dream abou...</td>\n",
       "      <td>17</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nThink!\\n\\nIt's the SCSI card doing the DMA t...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1)    I have an old Jasmine drive which I cann...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n\\nBack in high school I worked as a lab assi...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n\\nAE is in Dallas...try 214/241-6060 or 214/...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n[stuff deleted]\\n\\nOk, here's the solution t...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\n\\n\\nYeah, it's the second one.  And I believ...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\nIf a Christian means someone who believes in...</td>\n",
       "      <td>19</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  Target Label  \\\n",
       "0  \\n\\nI am sure some bashers of Pens fans are pr...            10   \n",
       "1  My brother is in the market for a high-perform...             3   \n",
       "2  \\n\\n\\n\\n\\tFinally you said what you dream abou...            17   \n",
       "3  \\nThink!\\n\\nIt's the SCSI card doing the DMA t...             3   \n",
       "4  1)    I have an old Jasmine drive which I cann...             4   \n",
       "5  \\n\\nBack in high school I worked as a lab assi...            12   \n",
       "6  \\n\\nAE is in Dallas...try 214/241-6060 or 214/...             4   \n",
       "7  \\n[stuff deleted]\\n\\nOk, here's the solution t...            10   \n",
       "8  \\n\\n\\nYeah, it's the second one.  And I believ...            10   \n",
       "9  \\nIf a Christian means someone who believes in...            19   \n",
       "\n",
       "                Target Name  \n",
       "0          rec.sport.hockey  \n",
       "1  comp.sys.ibm.pc.hardware  \n",
       "2     talk.politics.mideast  \n",
       "3  comp.sys.ibm.pc.hardware  \n",
       "4     comp.sys.mac.hardware  \n",
       "5           sci.electronics  \n",
       "6     comp.sys.mac.hardware  \n",
       "7          rec.sport.hockey  \n",
       "8          rec.sport.hockey  \n",
       "9        talk.religion.misc  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus, target_labels, target_names = (data.data, data.target,\n",
    "                                       [data_labels_map[label] for label in data.target])\n",
    "data_df = pd.DataFrame({'Article': corpus, 'Target Label': target_labels, 'Target Name': target_names})\n",
    "print(data_df.shape)\n",
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T21:34:24.451150Z",
     "start_time": "2020-04-04T21:34:24.348406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty documents: 515\n"
     ]
    }
   ],
   "source": [
    "total_nulls = data_df[data_df.Article.str.strip() == ''].shape[0]\n",
    "print(\"Empty documents:\", total_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T21:34:25.720761Z",
     "start_time": "2020-04-04T21:34:25.611022Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18331, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing nan values\n",
    "data_df = data_df[~(data_df.Article.str.strip() == '')]\n",
    "data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T21:34:26.975462Z",
     "start_time": "2020-04-04T21:34:26.893592Z"
    }
   },
   "outputs": [],
   "source": [
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Core\n",
    "\n",
    "The preprocessing step takes about 20 minutes using one core."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T21:17:11.369469Z",
     "start_time": "2020-04-04T20:59:23.511607Z"
    }
   },
   "outputs": [],
   "source": [
    "norm_corpus = tn.normalize_corpus(corpus=data_df['Article'])\n",
    "data_df['Clean Article1'] = norm_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the new clean data into column Clean Article1. Below is what the data look like after processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T21:17:12.657911Z",
     "start_time": "2020-04-04T21:17:12.521846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Clean Article1</th>\n",
       "      <th>Target Label</th>\n",
       "      <th>Target Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nI am sure some bashers of Pens fans are pr...</td>\n",
       "      <td>sure basher pen fan pretty confused lack kind ...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My brother is in the market for a high-perform...</td>\n",
       "      <td>brother market high performance video card sup...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\n\\n\\tFinally you said what you dream abou...</td>\n",
       "      <td>&amp;#9; finally say dream mediterranean new &amp;#9; ...</td>\n",
       "      <td>17</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nThink!\\n\\nIt's the SCSI card doing the DMA t...</td>\n",
       "      <td>think scsi card dma transfer disk scsi card dm...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1)    I have an old Jasmine drive which I cann...</td>\n",
       "      <td>old jasmine drive use new system understanding...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n\\nBack in high school I worked as a lab assi...</td>\n",
       "      <td>back high school work lab assistant bunch expe...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n\\nAE is in Dallas...try 214/241-6060 or 214/...</td>\n",
       "      <td>ae dalla try tech support may line one get start</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n[stuff deleted]\\n\\nOk, here's the solution t...</td>\n",
       "      <td>[ stuff delete ] ok solution problem move cana...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\n\\n\\nYeah, it's the second one.  And I believ...</td>\n",
       "      <td>yeah second one believe price try get good loo...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\nIf a Christian means someone who believes in...</td>\n",
       "      <td>christian mean someone believe divinity jesus ...</td>\n",
       "      <td>19</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  \\\n",
       "0  \\n\\nI am sure some bashers of Pens fans are pr...   \n",
       "1  My brother is in the market for a high-perform...   \n",
       "2  \\n\\n\\n\\n\\tFinally you said what you dream abou...   \n",
       "3  \\nThink!\\n\\nIt's the SCSI card doing the DMA t...   \n",
       "4  1)    I have an old Jasmine drive which I cann...   \n",
       "5  \\n\\nBack in high school I worked as a lab assi...   \n",
       "6  \\n\\nAE is in Dallas...try 214/241-6060 or 214/...   \n",
       "7  \\n[stuff deleted]\\n\\nOk, here's the solution t...   \n",
       "8  \\n\\n\\nYeah, it's the second one.  And I believ...   \n",
       "9  \\nIf a Christian means someone who believes in...   \n",
       "\n",
       "                                      Clean Article1  Target Label  \\\n",
       "0  sure basher pen fan pretty confused lack kind ...            10   \n",
       "1  brother market high performance video card sup...             3   \n",
       "2  &#9; finally say dream mediterranean new &#9; ...            17   \n",
       "3  think scsi card dma transfer disk scsi card dm...             3   \n",
       "4  old jasmine drive use new system understanding...             4   \n",
       "5  back high school work lab assistant bunch expe...            12   \n",
       "6   ae dalla try tech support may line one get start             4   \n",
       "7  [ stuff delete ] ok solution problem move cana...            10   \n",
       "8  yeah second one believe price try get good loo...            10   \n",
       "9  christian mean someone believe divinity jesus ...            19   \n",
       "\n",
       "                Target Name  \n",
       "0          rec.sport.hockey  \n",
       "1  comp.sys.ibm.pc.hardware  \n",
       "2     talk.politics.mideast  \n",
       "3  comp.sys.ibm.pc.hardware  \n",
       "4     comp.sys.mac.hardware  \n",
       "5           sci.electronics  \n",
       "6     comp.sys.mac.hardware  \n",
       "7          rec.sport.hockey  \n",
       "8          rec.sport.hockey  \n",
       "9        talk.religion.misc  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = data_df[['Article', 'Clean Article1', 'Target Label', 'Target Name']]\n",
    "data_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Preprocessing\n",
    "\n",
    "There's a significant decrease in time processing text with multi-core."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T21:43:38.597337Z",
     "start_time": "2020-04-04T21:34:43.107582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 535.3095 seconds with 6 process(es).\n"
     ]
    }
   ],
   "source": [
    "norm_corpus = tn.parallel_normalize_corpus(n_processes=6,corpus=data_df['Article'].values)\n",
    "data_df['Clean Article'] = norm_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T21:47:27.615930Z",
     "start_time": "2020-04-04T21:47:27.522181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Clean Article</th>\n",
       "      <th>Target Label</th>\n",
       "      <th>Target Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nI am sure some bashers of Pens fans are pr...</td>\n",
       "      <td>sure basher pen fan pretty confused lack kind ...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My brother is in the market for a high-perform...</td>\n",
       "      <td>brother market high performance video card sup...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\n\\n\\tFinally you said what you dream abou...</td>\n",
       "      <td>&amp;#9; finally say dream mediterranean new &amp;#9; ...</td>\n",
       "      <td>17</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nThink!\\n\\nIt's the SCSI card doing the DMA t...</td>\n",
       "      <td>think scsi card dma transfer disk scsi card dm...</td>\n",
       "      <td>3</td>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1)    I have an old Jasmine drive which I cann...</td>\n",
       "      <td>old jasmine drive use new system understanding...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n\\nBack in high school I worked as a lab assi...</td>\n",
       "      <td>back high school work lab assistant bunch expe...</td>\n",
       "      <td>12</td>\n",
       "      <td>sci.electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n\\nAE is in Dallas...try 214/241-6060 or 214/...</td>\n",
       "      <td>ae dalla try tech support may line one get start</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\n[stuff deleted]\\n\\nOk, here's the solution t...</td>\n",
       "      <td>[ stuff delete ] ok solution problem move cana...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\n\\n\\nYeah, it's the second one.  And I believ...</td>\n",
       "      <td>yeah second one believe price try get good loo...</td>\n",
       "      <td>10</td>\n",
       "      <td>rec.sport.hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\nIf a Christian means someone who believes in...</td>\n",
       "      <td>christian mean someone believe divinity jesus ...</td>\n",
       "      <td>19</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  \\\n",
       "0  \\n\\nI am sure some bashers of Pens fans are pr...   \n",
       "1  My brother is in the market for a high-perform...   \n",
       "2  \\n\\n\\n\\n\\tFinally you said what you dream abou...   \n",
       "3  \\nThink!\\n\\nIt's the SCSI card doing the DMA t...   \n",
       "4  1)    I have an old Jasmine drive which I cann...   \n",
       "5  \\n\\nBack in high school I worked as a lab assi...   \n",
       "6  \\n\\nAE is in Dallas...try 214/241-6060 or 214/...   \n",
       "7  \\n[stuff deleted]\\n\\nOk, here's the solution t...   \n",
       "8  \\n\\n\\nYeah, it's the second one.  And I believ...   \n",
       "9  \\nIf a Christian means someone who believes in...   \n",
       "\n",
       "                                       Clean Article  Target Label  \\\n",
       "0  sure basher pen fan pretty confused lack kind ...            10   \n",
       "1  brother market high performance video card sup...             3   \n",
       "2  &#9; finally say dream mediterranean new &#9; ...            17   \n",
       "3  think scsi card dma transfer disk scsi card dm...             3   \n",
       "4  old jasmine drive use new system understanding...             4   \n",
       "5  back high school work lab assistant bunch expe...            12   \n",
       "6   ae dalla try tech support may line one get start             4   \n",
       "7  [ stuff delete ] ok solution problem move cana...            10   \n",
       "8  yeah second one believe price try get good loo...            10   \n",
       "9  christian mean someone believe divinity jesus ...            19   \n",
       "\n",
       "                Target Name  \n",
       "0          rec.sport.hockey  \n",
       "1  comp.sys.ibm.pc.hardware  \n",
       "2     talk.politics.mideast  \n",
       "3  comp.sys.ibm.pc.hardware  \n",
       "4     comp.sys.mac.hardware  \n",
       "5           sci.electronics  \n",
       "6     comp.sys.mac.hardware  \n",
       "7          rec.sport.hockey  \n",
       "8          rec.sport.hockey  \n",
       "9        talk.religion.misc  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save clean data to a csv file for later use\n",
    "data_df = data_df[['Article', 'Clean Article', 'Target Label', 'Target Name']]\n",
    "display(data_df.head(10))\n",
    "data_df.to_csv('Clean_data.csv', index=None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T21:45:44.613441Z",
     "start_time": "2020-04-04T21:45:43.399605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18331 entries, 0 to 18330\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Article        18331 non-null  object\n",
      " 1   Clean Article  18305 non-null  object\n",
      " 2   Target Label   18331 non-null  int64 \n",
      " 3   Target Name    18331 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 573.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# Read data back in\n",
    "data_df = pd.read_csv('Clean_data.csv')\n",
    "data_df = data_df.replace(r'^(\\s?)+$', np.nan, regex=True)\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T21:45:45.972807Z",
     "start_time": "2020-04-04T21:45:45.840125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18305 entries, 0 to 18304\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Article        18305 non-null  object\n",
      " 1   Clean Article  18305 non-null  object\n",
      " 2   Target Label   18305 non-null  int64 \n",
      " 3   Target Name    18305 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 572.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Dropping nan values\n",
    "data_df = data_df.dropna().reset_index(drop=True)\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T21:46:21.569652Z",
     "start_time": "2020-04-04T21:46:21.427033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12264,), (6041,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting Traing and Test sets\n",
    "train_corpus, test_corpus, train_label_nums, test_label_nums, train_label_names, test_label_names = train_test_split(np.array(data_df['Clean Article']),\n",
    "                                         np.array(data_df['Target Label']),\n",
    "                                         np.array(data_df['Target Name']),\n",
    "                                         test_size=0.33, random_state=42)\n",
    "train_corpus.shape, test_corpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T21:46:25.383286Z",
     "start_time": "2020-04-04T21:46:25.186784Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target Label</th>\n",
       "      <th>Train Count</th>\n",
       "      <th>Test Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>686</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>665</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>soc.religion.christian</td>\n",
       "      <td>664</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comp.graphics</td>\n",
       "      <td>658</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rec.motorcycles</td>\n",
       "      <td>653</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>comp.windows.x</td>\n",
       "      <td>649</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rec.autos</td>\n",
       "      <td>642</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>636</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>comp.sys.ibm.pc.hardware</td>\n",
       "      <td>634</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sci.electronics</td>\n",
       "      <td>634</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>misc.forsale</td>\n",
       "      <td>633</td>\n",
       "      <td>326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>631</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sci.med</td>\n",
       "      <td>624</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sci.space</td>\n",
       "      <td>623</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "      <td>617</td>\n",
       "      <td>329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>talk.politics.mideast</td>\n",
       "      <td>609</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>talk.politics.guns</td>\n",
       "      <td>581</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>508</td>\n",
       "      <td>271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>talk.politics.misc</td>\n",
       "      <td>503</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>talk.religion.misc</td>\n",
       "      <td>414</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Target Label  Train Count  Test Count\n",
       "12          rec.sport.hockey          686         288\n",
       "11                 sci.crypt          665         297\n",
       "7     soc.religion.christian          664         310\n",
       "2              comp.graphics          658         295\n",
       "0            rec.motorcycles          653         316\n",
       "14            comp.windows.x          649         331\n",
       "18                 rec.autos          642         293\n",
       "3         rec.sport.baseball          636         315\n",
       "17  comp.sys.ibm.pc.hardware          634         329\n",
       "1            sci.electronics          634         322\n",
       "16              misc.forsale          633         326\n",
       "5      comp.sys.mac.hardware          631         296\n",
       "4                    sci.med          624         336\n",
       "9                  sci.space          623         330\n",
       "10   comp.os.ms-windows.misc          617         329\n",
       "15     talk.politics.mideast          609         309\n",
       "8         talk.politics.guns          581         305\n",
       "13               alt.atheism          508         271\n",
       "6         talk.politics.misc          503         252\n",
       "19        talk.religion.misc          414         191"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of data after preprocessing\n",
    "trd = dict(Counter(train_label_names))\n",
    "tsd = dict(Counter(test_label_names))\n",
    "(pd.DataFrame([[key, trd[key], tsd[key]] for key in trd],\n",
    "             columns=['Target Label', 'Train Count', 'Test Count'])\n",
    ".sort_values(by=['Train Count', 'Test Count'],\n",
    "             ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T21:46:42.868674Z",
     "start_time": "2020-04-04T21:46:40.395079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW model:> Train features shape: (12264, 72430)  Test features shape: (6041, 72430)\n"
     ]
    }
   ],
   "source": [
    "# build BOW features on train articles\n",
    "cv = CountVectorizer(binary=False, min_df=0.0, max_df=1.0)\n",
    "cv_train_features = cv.fit_transform(train_corpus)\n",
    "# transform test articles into features\n",
    "cv_test_features = cv.transform(test_corpus)\n",
    "print('BOW model:> Train features shape:', cv_train_features.shape,\n",
    "      ' Test features shape:', cv_test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 72430 unique words in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T21:49:55.112660Z",
     "start_time": "2020-04-04T21:49:53.692513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.66517676 0.65527066 0.67576375 0.66149449 0.67567568]\n",
      "Mean CV Accuracy: 0.6666762646724255\n",
      "Test Accuracy: 0.6823373613640126\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Classifier\n",
    "mnb = MultinomialNB(alpha=1)\n",
    "mnb.fit(cv_train_features, train_label_names)\n",
    "mnb_bow_cv_scores = cross_val_score(mnb, cv_train_features, train_label_names, cv=5)\n",
    "mnb_bow_cv_mean_score = np.mean(mnb_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', mnb_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', mnb_bow_cv_mean_score)\n",
    "mnb_bow_test_score = mnb.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', mnb_bow_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T21:53:27.736078Z",
     "start_time": "2020-04-04T21:49:56.325416Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.69402682 0.68416768 0.71242363 0.69252756 0.6981982 ]\n",
      "Mean CV Accuracy: 0.6962687776514593\n",
      "Test Accuracy: 0.710643933123655\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(penalty='l2', max_iter=100, C=1, random_state=42)\n",
    "lr.fit(cv_train_features, train_label_names)\n",
    "lr_bow_cv_scores = cross_val_score(lr, cv_train_features, train_label_names, cv=5)\n",
    "lr_bow_cv_mean_score = np.mean(lr_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', lr_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', lr_bow_cv_mean_score)\n",
    "lr_bow_test_score = lr.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', lr_bow_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T21:54:05.298276Z",
     "start_time": "2020-04-04T21:53:28.967784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.63348232 0.63003663 0.65580448 0.64679461 0.63963964]\n",
      "Mean CV Accuracy: 0.6411515369262697\n",
      "Test Accuracy: 0.6553550736633008\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "svm = LinearSVC(penalty='l2', C=1, random_state=42)\n",
    "svm.fit(cv_train_features, train_label_names)\n",
    "svm_bow_cv_scores = cross_val_score(svm, cv_train_features, train_label_names, cv=5)\n",
    "svm_bow_cv_mean_score = np.mean(svm_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', svm_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', svm_bow_cv_mean_score)\n",
    "svm_bow_test_score = svm.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', svm_bow_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T21:54:09.336101Z",
     "start_time": "2020-04-04T21:54:06.540919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.62454287 0.62108262 0.64154786 0.64189465 0.63472563]\n",
      "Mean CV Accuracy: 0.6327587273891667\n",
      "Test Accuracy: 0.6571759642443304\n"
     ]
    }
   ],
   "source": [
    "# SVM with Stochastic Gradient Descent\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "svm_sgd = SGDClassifier(loss='hinge', penalty=\"l2\", max_iter=5, random_state=42)\n",
    "svm_sgd.fit(cv_train_features, train_label_names)\n",
    "svmsgd_bow_cv_scores = cross_val_score(svm_sgd, cv_train_features, train_label_names, cv=5)\n",
    "svmsgd_bow_cv_mean_score = np.mean(svmsgd_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', svmsgd_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', svmsgd_bow_cv_mean_score)\n",
    "svmsgd_bow_test_score = svm_sgd.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', svmsgd_bow_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T21:54:58.784378Z",
     "start_time": "2020-04-04T21:54:10.561825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.52783421 0.50834351 0.5299389  0.50918742 0.53931204]\n",
      "Mean CV Accuracy: 0.5229232170063212\n",
      "Test Accuracy: 0.5326932627048502\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rfc.fit(cv_train_features, train_label_names)\n",
    "rfc_bow_cv_scores = cross_val_score(rfc, cv_train_features, train_label_names, cv=5)\n",
    "rfc_bow_cv_mean_score = np.mean(rfc_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', rfc_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', rfc_bow_cv_mean_score)\n",
    "rfc_bow_test_score = rfc.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', rfc_bow_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T22:03:55.414065Z",
     "start_time": "2020-04-04T21:55:00.052954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.54530679 0.55677656 0.54949084 0.54920376 0.54709255]\n",
      "Mean CV Accuracy: 0.5495740962788843\n",
      "Test Accuracy: 0.5515643105446119\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Machines\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier(n_estimators=10, random_state=42)\n",
    "gbc.fit(cv_train_features, train_label_names)\n",
    "gbc_bow_cv_scores = cross_val_score(gbc, cv_train_features, train_label_names, cv=5)\n",
    "gbc_bow_cv_mean_score = np.mean(gbc_bow_cv_scores)\n",
    "print('CV Accuracy (5-fold):', gbc_bow_cv_scores)\n",
    "print('Mean CV Accuracy:', gbc_bow_cv_mean_score)\n",
    "gbc_bow_test_score = gbc.score(cv_test_features, test_label_names)\n",
    "print('Test Accuracy:', gbc_bow_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-Idf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T23:00:53.540433Z",
     "start_time": "2020-04-04T23:00:51.146776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFIDF model:> Train features shape: (12264, 72430)  Test features shape: (6041, 72430)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# build BOW features on train articles\n",
    "tv = TfidfVectorizer(use_idf=True, min_df=0.0, max_df=1.0)\n",
    "tv_train_features = tv.fit_transform(train_corpus)\n",
    "# transform test articles into features\n",
    "tv_test_features = tv.transform(test_corpus)\n",
    "print('TFIDF model:> Train features shape:', tv_train_features.shape,\n",
    "      ' Test features shape:', tv_test_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, there are 72430 unique tf-idf features in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T23:00:58.974266Z",
     "start_time": "2020-04-04T23:00:57.680536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.70174726 0.6955637  0.73197556 0.70681911 0.70966421]\n",
      "Mean CV Accuracy: 0.7091539664725277\n",
      "Test Accuracy: 0.7194173150140705\n"
     ]
    }
   ],
   "source": [
    "# Naïve Bayes\n",
    "mnb = MultinomialNB(alpha=1)\n",
    "mnb.fit(tv_train_features, train_label_names)\n",
    "mnb_tfidf_cv_scores = cross_val_score(mnb, tv_train_features, train_label_names, cv=5)\n",
    "mnb_tfidf_cv_mean_score = np.mean(mnb_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', mnb_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', mnb_tfidf_cv_mean_score)\n",
    "mnb_tfidf_test_score = mnb.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', mnb_tfidf_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T23:01:23.241368Z",
     "start_time": "2020-04-04T23:01:00.295732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.73587972 0.72364672 0.75356415 0.74642711 0.74160524]\n",
      "Mean CV Accuracy: 0.7402245913670127\n",
      "Test Accuracy: 0.7505379903989405\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression(penalty='l2', max_iter=100, C=1, random_state=42)\n",
    "lr.fit(tv_train_features, train_label_names)\n",
    "lr_tfidf_cv_scores = cross_val_score(lr, tv_train_features, \n",
    "                                     train_label_names, cv=5,\n",
    "                                    n_jobs=6)\n",
    "lr_tfidf_cv_mean_score = np.mean(lr_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', lr_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', lr_tfidf_cv_mean_score)\n",
    "lr_tfidf_test_score = lr.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', lr_tfidf_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T23:01:31.718696Z",
     "start_time": "2020-04-04T23:01:24.521940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.74766355 0.73992674 0.77759674 0.76112699 0.75962326]\n",
      "Mean CV Accuracy: 0.7571874565808953\n",
      "Test Accuracy: 0.7664293991061083\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machines\n",
    "svm = LinearSVC(penalty='l2', C=1, random_state=42)\n",
    "svm.fit(tv_train_features, train_label_names)\n",
    "svm_tfidf_cv_scores = cross_val_score(svm, tv_train_features, train_label_names, cv=5, n_jobs = 6)\n",
    "svm_tfidf_cv_mean_score = np.mean(svm_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', svm_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', svm_tfidf_cv_mean_score)\n",
    "svm_tfidf_test_score = svm.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', svm_tfidf_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T23:01:36.512876Z",
     "start_time": "2020-04-04T23:01:32.969353Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.75497765 0.74277574 0.77230143 0.76847693 0.75675676]\n",
      "Mean CV Accuracy: 0.7590577011829144\n",
      "Test Accuracy: 0.7639463664956133\n"
     ]
    }
   ],
   "source": [
    "# SVM with Stochastic Gradient Descent\n",
    "svm_sgd = SGDClassifier(loss='hinge', penalty=\"l2\", max_iter=5, random_state=42)\n",
    "svm_sgd.fit(tv_train_features, train_label_names)\n",
    "svmsgd_tfidf_cv_scores = cross_val_score(svm_sgd, tv_train_features, train_label_names, cv=5, n_jobs=6)\n",
    "svmsgd_tfidf_cv_mean_score = np.mean(svmsgd_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', svmsgd_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', svmsgd_tfidf_cv_mean_score)\n",
    "svmsgd_tfidf_test_score = svm_sgd.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', svmsgd_tfidf_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T23:01:58.434613Z",
     "start_time": "2020-04-04T23:01:37.765556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.52580252 0.55270655 0.53564155 0.5320539  0.51924652]\n",
      "Mean CV Accuracy: 0.5330902077333027\n",
      "Test Accuracy: 0.5437841416983943\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rfc = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rfc.fit(tv_train_features, train_label_names)\n",
    "rfc_tfidf_cv_scores = cross_val_score(rfc, tv_train_features, train_label_names, cv=5, n_jobs=6)\n",
    "rfc_tfidf_cv_mean_score = np.mean(rfc_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', rfc_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', rfc_tfidf_cv_mean_score)\n",
    "rfc_tfidf_test_score = rfc.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', rfc_tfidf_test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-04T23:06:11.466373Z",
     "start_time": "2020-04-04T23:01:59.744082Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Accuracy (5-fold): [0.54815116 0.55311355 0.55885947 0.55042875 0.55159705]\n",
      "Mean CV Accuracy: 0.5524299959343953\n",
      "Test Accuracy: 0.5542128786624732\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "gbc = GradientBoostingClassifier(n_estimators=10, random_state=42)\n",
    "gbc.fit(tv_train_features, train_label_names)\n",
    "gbc_tfidf_cv_scores = cross_val_score(gbc, tv_train_features, train_label_names, cv=5, n_jobs=6)\n",
    "gbc_tfidf_cv_mean_score = np.mean(gbc_tfidf_cv_scores)\n",
    "print('CV Accuracy (5-fold):', gbc_tfidf_cv_scores)\n",
    "print('Mean CV Accuracy:', gbc_tfidf_cv_mean_score)\n",
    "gbc_tfidf_test_score = gbc.score(tv_test_features, test_label_names)\n",
    "print('Test Accuracy:', gbc_tfidf_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T20:35:09.593597Z",
     "start_time": "2020-03-28T20:35:09.585636Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        \\n\\nI am sure some bashers of Pens fans are pr...\n",
       "1        My brother is in the market for a high-perform...\n",
       "2        \\n\\n\\n\\n\\tFinally you said what you dream abou...\n",
       "3        \\nThink!\\n\\nIt's the SCSI card doing the DMA t...\n",
       "4        1)    I have an old Jasmine drive which I cann...\n",
       "                               ...                        \n",
       "18300    DN> From: nyeda@cnsvax.uwec.edu (David Nye)\\nD...\n",
       "18301    \\nNot in isolated ground recepticles (usually ...\n",
       "18302    I just installed a DX2-66 CPU in a clone mothe...\n",
       "18303    \\nWouldn't this require a hyper-sphere.  In 3-...\n",
       "18304    After a tip from Gary Crum (crum@fcom.cc.utah....\n",
       "Name: Article, Length: 18305, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['Article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "maxlen = 100                                           \n",
    "training_samples = 200                                 \n",
    "validation_samples = 10000                             \n",
    "max_words = 10000   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Not now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T05:00:01.904887Z",
     "start_time": "2020-03-27T05:00:01.896908Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def document_vectorizer(corpus, model, num_features):\n",
    "    vocabulary = set(model.wv.index2word)\n",
    "    def average_word_vectors(words, model, vocabulary, num_features):\n",
    "        feature_vector = np.zeros((num_features,), dtype=\"float64\")\n",
    "        nwords = 0.\n",
    "        for word in words:\n",
    "            if word in vocabulary:\n",
    "                nwords = nwords + 1.\n",
    "                feature_vector = np.add(feature_vector, model.wv[word])\n",
    "        if nwords:\n",
    "            feature_vector = np.divide(feature_vector, nwords)\n",
    "        return feature_vector\n",
    "    features = [average_word_vectors(tokenized_sentence, model, vocabulary, num_features) for tokenized_sentence in corpus]\n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T05:04:21.021585Z",
     "start_time": "2020-03-27T05:04:15.826453Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "DistributionNotFound",
     "evalue": "The 'pyasn1-modules>=0.2.1' distribution was not found and is required by google-auth",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDistributionNotFound\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-2b9d4549d7b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                    for text in test_corpus]\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# generate word2vec word embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m# build word2vec model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mw2v_num_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\nlpiaenv\\lib\\site-packages\\gensim\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \"\"\"\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mparsing\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterfaces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimilarities\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummarization\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[1;31m# noqa:F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\nlpiaenv\\lib\\site-packages\\gensim\\parsing\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m  \u001b[1;31m# noqa:F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m from .preprocessing import (remove_stopwords, strip_punctuation, strip_punctuation2,  # noqa:F401\n\u001b[0m\u001b[0;32m      5\u001b[0m                             \u001b[0mstrip_tags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrip_short\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrip_numeric\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                             \u001b[0mstrip_non_alphanum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrip_multiple_whitespaces\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\nlpiaenv\\lib\\site-packages\\gensim\\parsing\\preprocessing.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparsing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\nlpiaenv\\lib\\site-packages\\gensim\\utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msmart_open\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmultiprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcpu_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\nlpiaenv\\lib\\site-packages\\smart_open\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msmart_open\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0msmart_open_lib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregister_compressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0ms3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0miter_bucket\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0ms3_iter_bucket\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'open'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'smart_open'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m's3_iter_bucket'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'register_compressor'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\nlpiaenv\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhttp\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msmart_open_http\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mssh\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msmart_open_ssh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0msmart_open\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgcs\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msmart_open_gcs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msmart_open\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdoctools\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\nlpiaenv\\lib\\site-packages\\smart_open\\gcs.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransport\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequests\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgoogle_requests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\nlpiaenv\\lib\\site-packages\\google\\cloud\\exceptions.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi_core\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\nlpiaenv\\lib\\site-packages\\google\\api_core\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0m__version__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_distribution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"google-api-core\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\envs\\nlpiaenv\\lib\\site-packages\\pkg_resources\\__init__.py\u001b[0m in \u001b[0;36mget_distribution\u001b[1;34m(dist)\u001b[0m\n\u001b[0;32m    480\u001b[0m         \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRequirement\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRequirement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m         \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_provider\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDistribution\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expected string, Requirement, or Distribution\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\nlpiaenv\\lib\\site-packages\\pkg_resources\\__init__.py\u001b[0m in \u001b[0;36mget_provider\u001b[1;34m(moduleOrReq)\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[1;34m\"\"\"Return an IResourceProvider for the named module or requirement\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmoduleOrReq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRequirement\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mworking_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmoduleOrReq\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mrequire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmoduleOrReq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmoduleOrReq\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\nlpiaenv\\lib\\site-packages\\pkg_resources\\__init__.py\u001b[0m in \u001b[0;36mrequire\u001b[1;34m(self, *requirements)\u001b[0m\n\u001b[0;32m    899\u001b[0m         \u001b[0mincluded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meven\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mwere\u001b[0m \u001b[0malready\u001b[0m \u001b[0mactivated\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mworking\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m         \"\"\"\n\u001b[1;32m--> 901\u001b[1;33m         \u001b[0mneeded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparse_requirements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequirements\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mneeded\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\nlpiaenv\\lib\\site-packages\\pkg_resources\\__init__.py\u001b[0m in \u001b[0;36mresolve\u001b[1;34m(self, requirements, env, installer, replace_conflicting, extras)\u001b[0m\n\u001b[0;32m    785\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mdist\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m                         \u001b[0mrequirers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequired_by\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mDistributionNotFound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequirers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m                 \u001b[0mto_activate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdist\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDistributionNotFound\u001b[0m: The 'pyasn1-modules>=0.2.1' distribution was not found and is required by google-auth"
     ]
    }
   ],
   "source": [
    "# tokenize corpus\n",
    "tokenized_train = [tn.tokenizer.tokenize(text)\n",
    "                   for text in train_corpus]\n",
    "tokenized_test = [tn.tokenizer.tokenize(text)\n",
    "                   for text in test_corpus]\n",
    "# generate word2vec word embeddings\n",
    "import gensim\n",
    "# build word2vec model\n",
    "w2v_num_features = 1000\n",
    "w2v_model = gensim.models.Word2Vec(tokenized_train, size=w2v_num_features, window=100, min_count=2, sample=1e-3, sg=1, iter=5, workers=10)\n",
    "# generate document level embeddings\n",
    "# remember we only use train dataset vocabulary embeddings\n",
    "# so that test dataset truly remains an unseen dataset\n",
    "# generate averaged word vector features from word2vec model\n",
    "avg_wv_train_features = document_vectorizer(corpus=tokenized_train, model=w2v_model, num_features=w2v_num_features)\n",
    "avg_wv_test_features = document_vectorizer(corpus=tokenized_test, model=w2v_model, num_features=w2v_num_features)\n",
    "print('Word2Vec model:> Train features shape:', avg_wv_train_features.shape,' Test features shape:', avg_wv_test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
